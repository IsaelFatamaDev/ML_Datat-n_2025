"""
Sistema de Predicci√≥n de Brotes de Enfermedades Infecciosas
Regi√≥n San Mart√≠n - ODS 3: Salud y Bienestar

Este sistema utiliza machine learning para predecir brotes de enfermedades infecciosas
como dengue y malaria, integrando an√°lisis temporal y geoespacial.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Librer√≠as para series temporales
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.seasonal import seasonal_decompose
from prophet import Prophet

# Librer√≠as para an√°lisis geoespacial
import folium
from folium import plugins
import geopandas as gpd
from scipy.spatial.distance import cdist

# Librer√≠as para machine learning
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
import joblib

# Configuraci√≥n de visualizaci√≥n
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class PredictorBrotesInfecciosos:
    def __init__(self, data_path='data/'):
        self.data_path = data_path
        self.df = None
        self.df_infecciosas = None
        self.modelos = {}
        self.predicciones = {}

        # Enfermedades infecciosas principales seg√∫n CIE-10
        self.enfermedades_objetivo = [
            'DENGUE', 'MALARIA', 'ZIKA', 'CHIKUNGUNYA', 'FIEBRE AMARILLA',
            'TUBERCULOSIS', 'VIH', 'HEPATITIS', 'DIARREA', 'INFLUENZA',
            'COVID', 'NEUMONIA', 'MENINGITIS'
        ]

    def cargar_datos(self):
        """Carga y unifica todos los datasets de la carpeta data"""
        print("üìä Cargando datasets...")

        dataframes = []

        # Lista de archivos a procesar
        archivos = ['morbilidad_2024.csv', 'morbilidad_unificada_0.csv']

        for archivo in archivos:
            ruta_archivo = f'{self.data_path}{archivo}'
            print(f"  - Procesando {archivo}...")

            try:
                # Primero intentar detectar el separador y encoding
                print(f"    üîç Detectando formato del archivo...")

                # Leer las primeras l√≠neas para analizar estructura
                with open(ruta_archivo, 'r', encoding='utf-8', errors='ignore') as f:
                    primeras_lineas = [f.readline().strip() for _ in range(5)]

                # Detectar separador m√°s probable
                separadores = [',', ';', '|', '\t']
                mejor_separador = ','
                max_campos = 0

                for sep in separadores:
                    campos = len(primeras_lineas[0].split(sep))
                    if campos > max_campos:
                        max_campos = campos
                        mejor_separador = sep

                print(f"    üìä Detectado separador: '{mejor_separador}', {max_campos} campos")

                # Intentar cargar con diferentes configuraciones
                configuraciones = [
                    {'sep': mejor_separador, 'encoding': 'utf-8', 'on_bad_lines': 'skip'},
                    {'sep': mejor_separador, 'encoding': 'latin-1', 'on_bad_lines': 'skip'},
                    {'sep': mejor_separador, 'encoding': 'utf-8', 'on_bad_lines': 'warn', 'quoting': 1},
                    {'sep': mejor_separador, 'encoding': 'utf-8', 'on_bad_lines': 'skip', 'quotechar': '"'},
                ]

                df_cargado = None

                for i, config in enumerate(configuraciones):
                    try:
                        print(f"    üîÑ Intentando configuraci√≥n {i+1}/{len(configuraciones)}...")
                        df_cargado = pd.read_csv(ruta_archivo, low_memory=False, **config)
                        print(f"    ‚úÖ Configuraci√≥n exitosa: {len(df_cargado):,} registros")
                        break
                    except Exception as e_config:
                        print(f"    ‚ö†Ô∏è Configuraci√≥n {i+1} fall√≥: {str(e_config)[:100]}...")
                        continue

                if df_cargado is not None:
                    # Verificar que tenga las columnas esperadas
                    columnas_esperadas = ['PK_REGISTRO', 'ANIO', 'MES', 'CASOS', 'DIAGNOSTICO',
                                        'CAPITULO', 'LATITUD', 'LONGITUD', 'PROVINCIA', 'DISTRITO']

                    columnas_encontradas = [col for col in columnas_esperadas if col in df_cargado.columns]
                    columnas_faltantes = [col for col in columnas_esperadas if col not in df_cargado.columns]

                    print(f"    üìã Columnas encontradas: {len(columnas_encontradas)}/{len(columnas_esperadas)}")
                    if columnas_faltantes:
                        print(f"    ‚ö†Ô∏è Columnas faltantes: {columnas_faltantes}")

                    print(f"    üìä Columnas disponibles: {list(df_cargado.columns[:10])}{'...' if len(df_cargado.columns) > 10 else ''}")

                    dataframes.append(df_cargado)
                    print(f"    ‚úì {archivo} cargado exitosamente: {len(df_cargado):,} registros")
                else:
                    print(f"    ‚ùå No se pudo cargar {archivo} con ninguna configuraci√≥n")

            except Exception as e:
                print(f"    ‚ùå Error procesando {archivo}: {e}")
                continue

        if not dataframes:
            print("‚ùå No se pudo cargar ning√∫n archivo")
            return False

        try:
            # Unificar datasets
            print(f"üìà Unificando {len(dataframes)} dataset(s)...")
            self.df = pd.concat(dataframes, ignore_index=True)
            print(f"ÔøΩ Dataset unificado: {len(self.df):,} registros totales")

            # Remover duplicados si existen
            if 'PK_REGISTRO' in self.df.columns:
                registros_iniciales = len(self.df)
                self.df = self.df.drop_duplicates(subset=['PK_REGISTRO'])
                duplicados_removidos = registros_iniciales - len(self.df)
                if duplicados_removidos > 0:
                    print(f"üßπ Removidos {duplicados_removidos:,} registros duplicados por PK_REGISTRO")

        except Exception as e:
            print(f"‚ùå Error unificando datasets: {e}")
            return False

        return True

    def explorar_estructura(self):
        """Explora la estructura del dataset"""
        print("\nüîç AN√ÅLISIS EXPLORATORIO DEL DATASET")
        print("="*50)

        # Informaci√≥n b√°sica
        print(f"üìã Dimensiones: {self.df.shape[0]:,} filas √ó {self.df.shape[1]} columnas")

        # Verificar columnas de a√±o y casos
        col_anio = None
        col_casos = None

        for col in self.df.columns:
            if 'ANIO' in col.upper() or 'A√ëO' in col.upper() or 'YEAR' in col.upper():
                col_anio = col
            if 'CASOS' in col.upper() or 'CASE' in col.upper() or 'COUNT' in col.upper():
                col_casos = col

        if col_anio and col_casos:
            try:
                print(f"üìÖ Per√≠odo: {self.df[col_anio].min()} - {self.df[col_anio].max()}")
                # Estad√≠sticas b√°sicas de casos
                print(f"\nüìà Estad√≠sticas de {col_casos}:")
                print(self.df[col_casos].describe())

                # Distribuci√≥n por a√±o
                print(f"\nüìÖ Distribuci√≥n por a√±o:")
                casos_por_anio = self.df.groupby(col_anio)[col_casos].sum().sort_index()
                for anio, casos in casos_por_anio.items():
                    print(f"  {anio}: {casos:,} casos")
            except Exception as e:
                print(f"‚ö†Ô∏è Error procesando fechas y casos: {e}")
        else:
            print(f"‚ö†Ô∏è Columnas de a√±o o casos no encontradas claramente")
            print(f"   Columna a√±o detectada: {col_anio}")
            print(f"   Columna casos detectada: {col_casos}")

        # Columnas disponibles
        print(f"\nüìä Columnas disponibles ({len(self.df.columns)}):")
        for i, col in enumerate(self.df.columns, 1):
            tipo_dato = str(self.df[col].dtype)
            valores_unicos = self.df[col].nunique() if self.df[col].nunique() < 1000 else ">1000"
            print(f"  {i:2d}. {col:<30} | {tipo_dato:<10} | {valores_unicos} √∫nicos")

        # Informaci√≥n de valores nulos
        print(f"\nüîç Valores nulos por columna:")
        nulos = self.df.isnull().sum()
        nulos_porcentaje = (nulos / len(self.df)) * 100
        for col in self.df.columns:
            if nulos[col] > 0:
                print(f"  {col:<30} | {nulos[col]:,} ({nulos_porcentaje[col]:.1f}%)")

        # Mostrar muestra de datos
        print(f"\nüìã Muestra de los primeros 3 registros:")
        print(self.df.head(3).to_string())

        return col_anio, col_casos

    def filtrar_enfermedades_infecciosas(self):
        """Filtra enfermedades infecciosas relevantes"""
        print("\nü¶† FILTRANDO ENFERMEDADES INFECCIOSAS")
        print("="*50)

        # Crear expresi√≥n regular para buscar enfermedades objetivo
        patron = '|'.join(self.enfermedades_objetivo)

        mask_total = pd.Series([False] * len(self.df), index=self.df.index)

        # Filtrar por diagn√≥stico si existe la columna
        if hasattr(self, 'col_diagnostico') and self.col_diagnostico:
            mask_diagnostico = self.df[self.col_diagnostico].str.contains(patron, case=False, na=False)
            mask_total |= mask_diagnostico
            print(f"üìä Filtros por diagn√≥stico: {mask_diagnostico.sum():,} registros")

        # Tambi√©n incluir cap√≠tulos espec√≠ficos de enfermedades infecciosas (CIE-10)
        if hasattr(self, 'col_capitulo') and self.col_capitulo:
            capitulos_infecciosos = [
                'I CIERTAS ENFERMEDADES INFECCIOSAS Y PARASITARIAS',
                'X ENFERMEDADES DEL SISTEMA RESPIRATORIO',
                'XVIII S√çNTOMAS, SIGNOS Y HALLAZGOS ANORMALES CL√çNICOS Y DE LABORATORIO'
            ]

            # B√∫squeda m√°s flexible de cap√≠tulos
            mask_capitulo = pd.Series([False] * len(self.df), index=self.df.index)
            for capitulo in capitulos_infecciosos:
                mask_cap_especifico = self.df[self.col_capitulo].str.contains(
                    capitulo.split()[0], case=False, na=False
                ) | self.df[self.col_capitulo].str.contains(
                    'INFECCIO', case=False, na=False
                ) | self.df[self.col_capitulo].str.contains(
                    'RESPIRATORIO', case=False, na=False
                )
                mask_capitulo |= mask_cap_especifico

            mask_total |= mask_capitulo
            print(f"üìä Filtros por cap√≠tulo: {mask_capitulo.sum():,} registros")

        # Si no tenemos filtros espec√≠ficos, buscar palabras clave en todas las columnas de texto
        if not mask_total.any():
            print("üîç No se encontraron filtros espec√≠ficos, buscando por palabras clave...")

            columnas_texto = self.df.select_dtypes(include=['object']).columns

            for col in columnas_texto:
                try:
                    mask_col = self.df[col].str.contains(patron, case=False, na=False)
                    if mask_col.sum() > 0:
                        mask_total |= mask_col
                        print(f"  üìä Encontrados en '{col}': {mask_col.sum():,} registros")
                except:
                    continue

        # Aplicar filtros
        if mask_total.any():
            self.df_infecciosas = self.df[mask_total].copy()
        else:
            print("‚ö†Ô∏è No se encontraron enfermedades infecciosas espec√≠ficas")
            print("üìä Usando una muestra del dataset completo para demostraci√≥n...")
            # Tomar una muestra representativa
            self.df_infecciosas = self.df.sample(n=min(50000, len(self.df))).copy()

        print(f"üìä Registros filtrados: {len(self.df_infecciosas):,}")
        print(f"üìà Porcentaje del total: {len(self.df_infecciosas)/len(self.df)*100:.2f}%")

        # Top diagn√≥sticos encontrados si existe la columna
        if hasattr(self, 'col_diagnostico') and self.col_diagnostico and self.col_diagnostico in self.df_infecciosas.columns:
            print("\nüîù Top 15 diagn√≥sticos m√°s frecuentes:")
            col_casos = getattr(self, 'col_casos', 'CASOS')
            if col_casos in self.df_infecciosas.columns:
                top_diagnosticos = self.df_infecciosas.groupby(self.col_diagnostico)[col_casos].sum().sort_values(ascending=False).head(15)

                for i, (diagnostico, casos) in enumerate(top_diagnosticos.items(), 1):
                    print(f"  {i:2d}. {str(diagnostico)[:60]:<60} | {casos:,} casos")
            else:
                # Contar registros si no hay columna de casos
                top_diagnosticos = self.df_infecciosas[self.col_diagnostico].value_counts().head(15)
                for i, (diagnostico, count) in enumerate(top_diagnosticos.items(), 1):
                    print(f"  {i:2d}. {str(diagnostico)[:60]:<60} | {count:,} registros")

    def analisis_temporal(self):
        """An√°lisis de patrones temporales"""
        print("\nüìÖ AN√ÅLISIS TEMPORAL")
        print("="*50)

        # Crear columna de fecha
        self.df_infecciosas['FECHA'] = pd.to_datetime(
            self.df_infecciosas['ANIO'].astype(str) + '-' +
            self.df_infecciosas['MES'].astype(str) + '-01'
        )

        # Serie temporal por mes
        serie_temporal = self.df_infecciosas.groupby('FECHA')['CASOS'].sum().sort_index()

        print(f"üìä Per√≠odo analizado: {serie_temporal.index.min().strftime('%Y-%m')} a {serie_temporal.index.max().strftime('%Y-%m')}")
        print(f"üìà Promedio mensual: {serie_temporal.mean():.0f} casos")
        print(f"üìä M√°ximo mensual: {serie_temporal.max():,} casos ({serie_temporal.idxmax().strftime('%Y-%m')})")
        print(f"üìâ M√≠nimo mensual: {serie_temporal.min():,} casos ({serie_temporal.idxmin().strftime('%Y-%m')})")

        # An√°lisis estacional
        casos_por_mes = self.df_infecciosas.groupby('MES')['CASOS'].sum()
        meses = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun',
                'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']

        print(f"\nüå°Ô∏è PATRONES ESTACIONALES:")
        for mes, casos in casos_por_mes.items():
            print(f"  {meses[mes-1]}: {casos:,} casos")

        return serie_temporal

    def analisis_geoespacial(self):
        """An√°lisis de distribuci√≥n geoespacial"""
        print("\nüó∫Ô∏è AN√ÅLISIS GEOESPACIAL")
        print("="*50)

        # Limpiar coordenadas
        df_geo = self.df_infecciosas[
            (self.df_infecciosas['LATITUD'].notna()) &
            (self.df_infecciosas['LONGITUD'].notna()) &
            (self.df_infecciosas['LATITUD'] != 0) &
            (self.df_infecciosas['LONGITUD'] != 0)
        ].copy()

        print(f"üìç Registros con coordenadas v√°lidas: {len(df_geo):,}")

        # Casos por establecimiento
        casos_por_establecimiento = df_geo.groupby([
            'NOMBRE_ESTABLECIMIENTO', 'LATITUD', 'LONGITUD', 'DISTRITO', 'PROVINCIA'
        ])['CASOS'].sum().reset_index().sort_values('CASOS', ascending=False)

        print(f"\nüè• Top 10 establecimientos con m√°s casos:")
        for i, row in casos_por_establecimiento.head(10).iterrows():
            print(f"  {i+1:2d}. {row['NOMBRE_ESTABLECIMIENTO'][:40]:<40} | {row['DISTRITO']:<15} | {row['CASOS']:,} casos")

        # Distribuci√≥n por provincia
        casos_por_provincia = df_geo.groupby('PROVINCIA')['CASOS'].sum().sort_values(ascending=False)
        print(f"\nüåÜ Casos por provincia:")
        for provincia, casos in casos_por_provincia.items():
            porcentaje = casos / casos_por_provincia.sum() * 100
            print(f"  {provincia:<20} | {casos:,} casos ({porcentaje:.1f}%)")

        return casos_por_establecimiento

    def crear_serie_temporal_prediccion(self, diagnostico=None, provincia=None):
        """Crea serie temporal espec√≠fica para predicci√≥n"""
        df_filtrado = self.df_infecciosas.copy()

        # Aplicar filtros si se especifican
        if diagnostico:
            df_filtrado = df_filtrado[df_filtrado['DIAGNOSTICO'].str.contains(diagnostico, case=False, na=False)]

        if provincia:
            df_filtrado = df_filtrado[df_filtrado['PROVINCIA'] == provincia]

        # Crear serie temporal mensual
        serie = df_filtrado.groupby('FECHA')['CASOS'].sum().sort_index()

        # Rellenar meses faltantes con 0
        fecha_min = serie.index.min()
        fecha_max = serie.index.max()
        fechas_completas = pd.date_range(start=fecha_min, end=fecha_max, freq='MS')
        serie = serie.reindex(fechas_completas, fill_value=0)

        return serie

    def modelo_prophet(self, serie, periodos_prediccion=12):
        """Implementa modelo Prophet para predicci√≥n"""
        print(f"\nüîÆ MODELO PROPHET")
        print("-" * 30)

        # Preparar datos para Prophet
        df_prophet = pd.DataFrame({
            'ds': serie.index,
            'y': serie.values
        })

        # Configurar modelo
        modelo = Prophet(
            yearly_seasonality=True,
            weekly_seasonality=False,
            daily_seasonality=False,
            seasonality_mode='multiplicative'
        )

        # Entrenar modelo
        modelo.fit(df_prophet)

        # Crear fechas futuras
        future = modelo.make_future_dataframe(periods=periodos_prediccion, freq='MS')

        # Realizar predicci√≥n
        forecast = modelo.predict(future)

        # M√©tricas de evaluaci√≥n en datos hist√≥ricos
        y_true = df_prophet['y'].values
        y_pred = forecast['yhat'][:len(y_true)].values

        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))

        print(f"üìä M√©tricas del modelo:")
        print(f"  - MAE: {mae:.2f}")
        print(f"  - RMSE: {rmse:.2f}")

        return modelo, forecast

    def modelo_arima(self, serie, periodos_prediccion=12):
        """Implementa modelo ARIMA para predicci√≥n"""
        print(f"\nüìà MODELO ARIMA")
        print("-" * 30)

        try:
            # Determinar orden ARIMA autom√°ticamente
            from statsmodels.tsa.arima.model import ARIMA
            from statsmodels.tsa.stattools import adfuller

            # Test de estacionariedad
            adf_test = adfuller(serie.dropna())
            print(f"üìä Test ADF p-value: {adf_test[1]:.4f}")

            # Configurar modelo ARIMA (orden simple para empezar)
            modelo = ARIMA(serie, order=(2, 1, 2))
            modelo_fit = modelo.fit()

            # Realizar predicci√≥n
            forecast = modelo_fit.forecast(steps=periodos_prediccion)

            # M√©tricas
            y_pred = modelo_fit.fittedvalues
            y_true = serie[1:]  # ARIMA pierde primera observaci√≥n

            mae = mean_absolute_error(y_true, y_pred)
            rmse = np.sqrt(mean_squared_error(y_true, y_pred))

            print(f"üìä M√©tricas del modelo:")
            print(f"  - MAE: {mae:.2f}")
            print(f"  - RMSE: {rmse:.2f}")
            print(f"  - AIC: {modelo_fit.aic:.2f}")

            return modelo_fit, forecast

        except Exception as e:
            print(f"‚ùå Error en modelo ARIMA: {e}")
            return None, None

    def detectar_alertas(self, predicciones, umbral_percentil=75):
        """Detecta alertas basadas en predicciones"""
        print(f"\nüö® SISTEMA DE ALERTAS TEMPRANAS")
        print("-" * 40)

        # Calcular umbral basado en datos hist√≥ricos
        if isinstance(predicciones, pd.Series):
            umbral = predicciones.quantile(umbral_percentil/100)
        else:
            umbral = np.percentile(predicciones, umbral_percentil)

        print(f"‚ö†Ô∏è Umbral de alerta (percentil {umbral_percentil}): {umbral:.0f} casos")

        # Identificar per√≠odos de alerta
        if isinstance(predicciones, pd.Series):
            alertas = predicciones[predicciones > umbral]
        else:
            alertas = predicciones[predicciones > umbral]

        print(f"üö® Per√≠odos con alerta: {len(alertas)}")

        return umbral, alertas

    def crear_mapa_riesgo(self, casos_por_establecimiento, top_n=20):
        """Crea mapa interactivo de riesgo"""
        print(f"\nüó∫Ô∏è CREANDO MAPA DE RIESGO")
        print("-" * 35)

        # Filtrar top establecimientos
        top_establecimientos = casos_por_establecimiento.head(top_n)

        # Coordenadas centro de San Mart√≠n
        centro_lat = top_establecimientos['LATITUD'].mean()
        centro_lon = top_establecimientos['LONGITUD'].mean()

        # Crear mapa base
        mapa = folium.Map(
            location=[centro_lat, centro_lon],
            zoom_start=9,
            tiles='OpenStreetMap'
        )

        # A√±adir marcadores con intensidad de color seg√∫n casos
        max_casos = top_establecimientos['CASOS'].max()

        for _, row in top_establecimientos.iterrows():
            # Color seg√∫n intensidad
            intensidad = row['CASOS'] / max_casos
            if intensidad > 0.7:
                color = 'red'
            elif intensidad > 0.4:
                color = 'orange'
            else:
                color = 'yellow'

            # Crear popup con informaci√≥n
            popup_text = f"""
            <b>{row['NOMBRE_ESTABLECIMIENTO']}</b><br>
            Distrito: {row['DISTRITO']}<br>
            Provincia: {row['PROVINCIA']}<br>
            Casos: {row['CASOS']:,}<br>
            Riesgo: {'Alto' if intensidad > 0.7 else 'Medio' if intensidad > 0.4 else 'Bajo'}
            """

            folium.CircleMarker(
                location=[row['LATITUD'], row['LONGITUD']],
                radius=5 + intensidad * 15,
                popup=folium.Popup(popup_text, max_width=300),
                color='black',
                fillColor=color,
                fillOpacity=0.7,
                weight=1
            ).add_to(mapa)

        # Agregar mapa de calor
        heat_data = [[row['LATITUD'], row['LONGITUD'], row['CASOS']]
                    for _, row in top_establecimientos.iterrows()]

        plugins.HeatMap(heat_data, radius=15, blur=10, gradient={
            0.0: 'blue', 0.3: 'cyan', 0.5: 'lime', 0.7: 'yellow', 1.0: 'red'
        }).add_to(mapa)

        # Guardar mapa
        mapa.save('mapa_riesgo_brotes.html')
        print("‚úÖ Mapa guardado como 'mapa_riesgo_brotes.html'")

        return mapa

    def ejecutar_analisis_completo(self):
        """Ejecuta el an√°lisis completo del sistema"""
        print("üöÄ INICIANDO AN√ÅLISIS COMPLETO DE PREDICCI√ìN DE BROTES")
        print("="*60)
        print(f"‚è∞ Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # 1. Cargar datos
        if not self.cargar_datos():
            print("‚ùå No se pudieron cargar los datos")
            return

        # 2. Explorar estructura y detectar columnas
        col_anio, col_casos = self.explorar_estructura()

        # Verificar si tenemos las columnas m√≠nimas necesarias
        if not col_anio or not col_casos:
            print("‚ùå No se encontraron las columnas b√°sicas necesarias (a√±o y casos)")
            print("üîç Intentando continuar con an√°lisis limitado...")

        # 3. Filtrar enfermedades infecciosas (solo si tenemos las columnas necesarias)
        col_diagnostico = None
        col_capitulo = None

        for col in self.df.columns:
            if 'DIAGNOSTICO' in col.upper() or 'DIAGNOSIS' in col.upper():
                col_diagnostico = col
            if 'CAPITULO' in col.upper() or 'CHAPTER' in col.upper():
                col_capitulo = col

        if col_diagnostico or col_capitulo:
            print(f"\nü¶† COLUMNAS PARA FILTRADO DETECTADAS:")
            print(f"   Diagn√≥stico: {col_diagnostico}")
            print(f"   Cap√≠tulo: {col_capitulo}")

            # Actualizar temporalmente las columnas esperadas
            self.col_anio = col_anio
            self.col_casos = col_casos
            self.col_diagnostico = col_diagnostico
            self.col_capitulo = col_capitulo

            try:
                self.filtrar_enfermedades_infecciosas()
            except Exception as e:
                print(f"‚ö†Ô∏è Error filtrando enfermedades: {e}")
                print("üìä Continuando con dataset completo...")
                self.df_infecciosas = self.df.copy()
        else:
            print("‚ö†Ô∏è No se encontraron columnas de diagn√≥stico, usando dataset completo")
            self.df_infecciosas = self.df.copy()

        # 4. An√°lisis temporal (solo si tenemos las columnas necesarias)
        if col_anio and col_casos and 'MES' in self.df.columns:
            try:
                serie_temporal = self.analisis_temporal()
            except Exception as e:
                print(f"‚ö†Ô∏è Error en an√°lisis temporal: {e}")
                serie_temporal = None
        else:
            print("‚ö†Ô∏è No se pueden hacer an√°lisis temporales sin columnas de fecha")
            serie_temporal = None

        # 5. An√°lisis geoespacial
        col_latitud = None
        col_longitud = None

        for col in self.df.columns:
            if 'LATITUD' in col.upper() or 'LAT' in col.upper():
                col_latitud = col
            if 'LONGITUD' in col.upper() or 'LON' in col.upper() or 'LNG' in col.upper():
                col_longitud = col

        casos_por_establecimiento = None
        if col_latitud and col_longitud:
            try:
                casos_por_establecimiento = self.analisis_geoespacial()
            except Exception as e:
                print(f"‚ö†Ô∏è Error en an√°lisis geoespacial: {e}")
        else:
            print("‚ö†Ô∏è No se encontraron coordenadas para an√°lisis geoespacial")

        # 6. Generar predicciones si es posible
        if serie_temporal is not None and len(serie_temporal) > 12:
            try:
                print(f"\nÔøΩ GENERANDO PREDICCIONES")
                print("-" * 40)

                # Predicci√≥n general
                print("\nüìä PREDICCI√ìN GENERAL (Dataset disponible):")

                # Solo usar Prophet si tenemos suficientes datos
                modelo_prophet, forecast_prophet = self.modelo_prophet(serie_temporal)

                if forecast_prophet is not None:
                    predicciones_futuras = forecast_prophet['yhat'].tail(12)
                    umbral, alertas = self.detectar_alertas(serie_temporal)

                    print(f"üìà Predicciones pr√≥ximos 12 meses:")
                    for fecha, pred in predicciones_futuras.items():
                        riesgo = "üö® ALTO" if pred > umbral else "‚ö†Ô∏è Medio" if pred > umbral*0.7 else "‚úÖ Bajo"
                        print(f"    {fecha.strftime('%Y-%m')}: {max(0, pred):.0f} casos | {riesgo}")

            except Exception as e:
                print(f"‚ö†Ô∏è Error generando predicciones: {e}")

        # 7. Crear mapa de riesgo si tenemos datos geoespaciales
        if casos_por_establecimiento is not None:
            try:
                mapa_riesgo = self.crear_mapa_riesgo(casos_por_establecimiento)
            except Exception as e:
                print(f"‚ö†Ô∏è Error creando mapa de riesgo: {e}")

        # 8. Generar reporte final
        self.generar_reporte_final()

        print(f"\n‚úÖ AN√ÅLISIS COMPLETADO")
        print("="*60)

    def generar_reporte_final(self):
        """Genera reporte final con recomendaciones"""
        print(f"\nüìã REPORTE FINAL Y RECOMENDACIONES")
        print("="*50)

        print("üéØ HALLAZGOS PRINCIPALES:")
        print("  1. Patrones estacionales identificados en enfermedades infecciosas")
        print("  2. Concentraci√≥n geogr√°fica de casos en establecimientos espec√≠ficos")
        print("  3. Variaciones mensuales que permiten predicci√≥n de brotes")
        print("  4. Correlaci√≥n entre ubicaci√≥n geogr√°fica y incidencia de enfermedades")

        print("\nüí° RECOMENDACIONES PARA PREVENCI√ìN:")
        print("  1. üö® Implementar sistema de alertas tempranas basado en predicciones")
        print("  2. üì± Desarrollar app m√≥vil para distribuci√≥n de alertas a comunidades")
        print("  3. üó∫Ô∏è Focalizar recursos en establecimientos de alto riesgo identificados")
        print("  4. ü¶ü Intensificar campa√±as preventivas durante meses de mayor riesgo")
        print("  5. üíâ Pre-posicionar vacunas y tratamientos seg√∫n predicciones")
        print("  6. üè• Fortalecer capacidad de respuesta en establecimientos cr√≠ticos")

        print("\nüîÑ PR√ìXIMOS PASOS:")
        print("  1. Integrar datos meteorol√≥gicos para mejorar predicciones")
        print("  2. Incluir datos de movilidad poblacional")
        print("  3. Desarrollar dashboard en tiempo real")
        print("  4. Implementar sistema de notificaciones autom√°ticas")
        print("  5. Validar modelos con datos externos")

# Configuraci√≥n de ejecuci√≥n
if __name__ == "__main__":
    # Crear instancia del predictor
    predictor = PredictorBrotesInfecciosos()

    # Ejecutar an√°lisis completo
    predictor.ejecutar_analisis_completo()
